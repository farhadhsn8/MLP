{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "implementationDynamicMLP.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyNMeVKQGyV7KRJIEYwzhFuy",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/farhadhsn8/MLP/blob/master/implementationDynamicMLP.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Attribute Information:\n",
        "\n",
        "1. sepal length in cm\n",
        "2. sepal width in cm\n",
        "3. petal length in cm\n",
        "4. petal width in cm\n",
        "\n",
        "## class:\n",
        "1. Iris Setosa\n",
        "2. Iris Versicolour\n",
        "3. Iris Virginica"
      ],
      "metadata": {
        "id": "oe3sbQBguksr"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 50,
      "metadata": {
        "id": "Iky3dAh7qIXZ"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "from sklearn import datasets\n",
        "import random\n",
        "import numpy as np\n",
        "import math\n",
        "iris = datasets.load_iris()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "iris = datasets.load_iris()\n",
        "features = iris.data  \n",
        "lables = iris.target\n",
        "type(features)\n",
        "features.shape   # (150, 4)\n",
        "lables.shape    # (150,)\n",
        "NUMBER_OF_OUTPUT = 2"
      ],
      "metadata": {
        "id": "0hG14l9kq5pd"
      },
      "execution_count": 51,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class MLP:\n",
        "\n",
        "  def __init__(self , feacturesOftrainingdata , lablesOftrainingdata):\n",
        "    self.feacturesOftrainingdata = feacturesOftrainingdata\n",
        "    self.lablesOftrainingdata = lablesOftrainingdata\n",
        "    self.slidingHead = 0\n",
        "    self.etha = float(input('enter learning rate :'))\n",
        "    self.numberOfLayers = int(input('enter number of layers :'))\n",
        "    self.layers =  np.empty(self.numberOfLayers,dtype=Layer)\n",
        "    self.makeLayers()\n",
        "    \n",
        "    \n",
        "\n",
        "  def makeLayers(self):\n",
        "    for i in range(self.numberOfLayers):\n",
        "      self.layers[i] = Layer(i , self)\n",
        "\n",
        "  def train(self):\n",
        "    return self.calculateMLP_outputForRow_k(self.getCurrentFeacherRow())\n",
        "\n",
        "\n",
        "  def calculateMLP_outputForRow_k(self, X):\n",
        "    return self.layers[self.numberOfLayers - 1].claculateLayerOutput()\n",
        "\n",
        "  def getCurrentFeacherRow(self):\n",
        "    return self.feacturesOftrainingdata[self.slidingHead]\n",
        "\n",
        "  def getCurrentLableRow(self):\n",
        "    return self.lablesOftrainingdata[self.slidingHead]\n",
        "\n",
        "\n",
        "\n",
        "#--------------------------------------------------------------------------\n",
        "\n",
        "\n",
        "class Layer:\n",
        "\n",
        "  def __init__(self,layerAddress , MLP):\n",
        "    self.MLP = MLP\n",
        "    self.layerAddress = layerAddress\n",
        "    self.numberOfPerceptrons = self.setNumberOfPerceptrons()\n",
        "    self.activityFunction = ActivityFunction(self)\n",
        "    self.perceptrons =  np.empty(self.numberOfPerceptrons,dtype=Perceptron)\n",
        "    self.perceptrons = self.makePerceptrons()\n",
        "    self.output = np.full((self.numberOfPerceptrons), math.inf)\n",
        "\n",
        "\n",
        "  def setNumberOfPerceptrons(self):\n",
        "    if(self.layerAddress == 0 ):\n",
        "      return  2 #features.shape[1] + 1  ###############\n",
        "    if(self.layerAddress == self.MLP.numberOfLayers - 1 ):\n",
        "      return  NUMBER_OF_OUTPUT\n",
        "    return int(input('enter number of Perceptrons for  layer '+ str(self.layerAddress  ) + ' (start layer number from 0) : '))\n",
        "\n",
        "  def makePerceptrons(self):\n",
        "    perceptrons =  np.empty(self.numberOfPerceptrons,dtype=Perceptron) \n",
        "    for i in range( self.numberOfPerceptrons ):\n",
        "      perceptrons[i] = Perceptron( i , self)\n",
        "    return perceptrons\n",
        "\n",
        "  def getPreviosLayer(self):\n",
        "    return self.layerAddress != 0 and self.MLP.layers[self.layerAddress - 1 ] or -1\n",
        "\n",
        "  \n",
        "  def getNextLayer(self):\n",
        "    return self.layerAddress != self.MLP.numberOfLayers - 1 \\\n",
        "     and self.MLP.layers[self.layerAddress + 1 ] or -1\n",
        "\n",
        "\n",
        "  def claculateLayerOutput(self):     # receive Vector   # return Vector\n",
        "    if (self.output[0] !=   math.inf):\n",
        "      print('oooookz',self.output)\n",
        "      return self.output\n",
        "    X = self.layerAddress==0 and self.MLP.getCurrentFeacherRow() or self.getPreviosLayer().claculateLayerOutput()\n",
        "    output =  np.empty(self.numberOfPerceptrons)\n",
        "    for i in range(self.numberOfPerceptrons):\n",
        "      output[i] =(self.layerAddress == 0) and self.perceptrons[i].calculatePerceptronOutput([X[i]]) \\\n",
        "       or self.perceptrons[i].calculatePerceptronOutput(X)\n",
        "    self.output = output\n",
        "    return output\n",
        "\n",
        "  def calculateDerivativeOfActivationFunction(self,net):\n",
        "    return self.activityFunction.calculateDerivative(net)\n",
        "\n",
        "\n",
        "\n",
        "#--------------------------------------------------------------------------\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "class ActivityFunction:\n",
        "  \n",
        "  def __init__(self,layer):\n",
        "    self.layer = layer\n",
        "    self.functionType = int(input('enter code of function for layer'+str(self.layer.layerAddress)+' =>[ 1.sigmoid  | 2.tanh  | 3.relu | 4.linear ] :'))\n",
        "  \n",
        "  def runActivationFunction(self,x):\n",
        "    if (self.functionType == 1) :\n",
        "      return self.sigmoid(x)\n",
        "    if (self.functionType == 2) :\n",
        "      return self.tanh(x)\n",
        "    if (self.functionType == 3) :\n",
        "      return self.ReLU(x)\n",
        "    if (self.functionType == 4) :\n",
        "      return self.linear(x)\n",
        "\n",
        "  def sigmoid(self, x):\n",
        "    return 1 / (1 + math.exp(-x))\n",
        "\n",
        "  def tanh(self , x):\n",
        "    t=(math.exp(x)-math.exp(-x))/(math.exp(x)+math.exp(-x))\n",
        "    return t\n",
        "\n",
        "  def ReLU(self ,x):\n",
        "    return max(0.0,x)\n",
        "\n",
        "  def linear(self , x):\n",
        "    return x\n",
        "\n",
        "  def calculateDerivative(self , net):\n",
        "    if (self.functionType == 1) :\n",
        "      sig = self.sigmoid(net)\n",
        "      return (1-sig)*sig\n",
        "    if (self.functionType == 2) :\n",
        "      return 1 - self.tanh(net)**2\n",
        "    if (self.functionType == 3) :\n",
        "      if(net<0):\n",
        "        return 0\n",
        "      return 1\n",
        "    if (self.functionType == 4) :\n",
        "      return 1\n",
        "\n",
        "\n",
        "\n",
        "#--------------------------------------------------------------------------\n",
        "\n",
        "\n",
        "class Perceptron:\n",
        "\n",
        "  \n",
        "\n",
        "  def __init__(self , perceptronNumber , layer ):   # [layerAddress  ,  perceptron] \n",
        "    self.perceptronNumber = perceptronNumber\n",
        "    self.layer = layer\n",
        "    self.numberOfInputs  =  self.getNumberOfInputs()\n",
        "    self.inputBranchs =  np.empty(self.numberOfInputs,dtype=Layer)\n",
        "    self.makeInputs()\n",
        "    self.delta = math.inf\n",
        "\n",
        "  def makeInputs(self):\n",
        "    for i in range(self.numberOfInputs):\n",
        "      self.inputBranchs[i] = InputBranch(self)\n",
        "\n",
        "  def getNumberOfInputs(self):\n",
        "    if(self.layer.layerAddress == 0 ):\n",
        "      return  1\n",
        "    return self.layer.getPreviosLayer().numberOfPerceptrons + 1\n",
        "\n",
        "  def calculatePerceptronOutput(self , X):\n",
        "        net = self.calculatePerceptronNet(X)\n",
        "        return self.layer.activityFunction.runActivationFunction(net)\n",
        "\n",
        "        \n",
        "  def calculatePerceptronNet(self , X):    # X is input feature vector\n",
        "        y=0\n",
        "        # DONT FORGET BAIAS\n",
        "        X = np.concatenate((X, [1]), axis=None)\n",
        "        for i in range(self.numberOfInputs):\n",
        "          y += self.inputBranchs[i].calculateBranchOutput(X[i])\n",
        "        return y\n",
        "\n",
        "\n",
        "  def getDelta(self):\n",
        "    desiredOutput = self.layer.MLP.getCurrentLableRow()[self.perceptronNumber]\n",
        "    X = (self.layer.layerAddress == 0)  and self.layer.MLP.getCurrentFeacherRow() or self.layer.getPreviosLayer().claculateLayerOutput()\n",
        "    if(self.delta == math.inf):\n",
        "      self.delta =  self.calculateDelta(X ,desiredOutput)\n",
        "      return self.calculateDelta(X ,desiredOutput)\n",
        "    print('ok',self.delta)\n",
        "    return self.delta\n",
        "\n",
        "  def calculateDelta(self,X , desiredOutput):  # X is input vector \n",
        "    net = self.calculatePerceptronNet(X)\n",
        "    if(self.layer.layerAddress == self.layer.MLP.numberOfLayers - 1):     # perceptron in output layer\n",
        "      return self.layer.calculateDerivativeOfActivationFunction(net) * ( desiredOutput - self.calculatePerceptronOutput(X))\n",
        "    else:       # perceptron in hidden layer\n",
        "      sigma = 0\n",
        "      layerOutput = self.layer.claculateLayerOutput()\n",
        "      for perceptron in self.layer.getNextLayer().perceptrons:\n",
        "        sigma += perceptron.inputBranchs[self.perceptronNumber].w * perceptron.getDelta() \n",
        "      return self.layer.calculateDerivativeOfActivationFunction(net) * sigma\n",
        "\n",
        "\n",
        "    \n",
        "\n",
        "\n",
        "  \n",
        "          \n",
        "\n",
        "\n",
        "    \n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "#--------------------------------------------------------------------------\n",
        "\n",
        "class InputBranch:\n",
        "  \n",
        "  def __init__(self , perceptron):\n",
        "    self.perceptron = perceptron\n",
        "    self.w = self.setW()\n",
        "    self.Wnew = self.w\n",
        "\n",
        "  def setW(self):\n",
        "    if(self.perceptron.layer.layerAddress == 0):\n",
        "      return 1\n",
        "    return 1#random.uniform(-3, 3)\n",
        "\n",
        "  def calculateBranchOutput(self , x):\n",
        "    return self.w * x \n",
        "\n",
        "  def updateW(self,desiredOutput):\n",
        "    Wnew = self.perceptron.layer.MLP.etha * self.perceptron.getDelta(desiredOutput)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "  \n",
        "\n",
        "\n",
        "\n",
        "  \n",
        "\n",
        "  \n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "eAQqhLzIsTfX"
      },
      "execution_count": 200,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "A = MLP([[1,2,3,]] , [[0,1,1]])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "doXsBMA0wh8K",
        "outputId": "0858e5ae-caf7-4a91-addd-f8604faca725"
      },
      "execution_count": 201,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "enter learning rate :1\n",
            "enter number of layers :3\n",
            "enter code of function for layer0 =>[ 1.sigmoid  | 2.tanh  | 3.relu | 4.linear ] :4\n",
            "enter number of Perceptrons for  layer 1 (start layer number from 0) : 2\n",
            "enter code of function for layer1 =>[ 1.sigmoid  | 2.tanh  | 3.relu | 4.linear ] :4\n",
            "enter code of function for layer2 =>[ 1.sigmoid  | 2.tanh  | 3.relu | 4.linear ] :4\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# shape of MLP\n",
        "for i in A.layers:\n",
        "  print(i)\n",
        "  for j in i.perceptrons:\n",
        "    print( j.numberOfInputs)"
      ],
      "metadata": {
        "id": "lVlOA3PMs-br",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d0b6e2c0-a86c-4b91-ea13-3ff66dd54ccc"
      },
      "execution_count": 202,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<__main__.Layer object at 0x7f6e6be07b10>\n",
            "1\n",
            "1\n",
            "<__main__.Layer object at 0x7f6e6bd99310>\n",
            "3\n",
            "3\n",
            "<__main__.Layer object at 0x7f6e6bdeb1d0>\n",
            "3\n",
            "3\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "A.train()\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Zx3cI2YuhIQ-",
        "outputId": "c7c9390c-30c8-40e8-c38b-66e8c1d86654"
      },
      "execution_count": 203,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([9., 9.])"
            ]
          },
          "metadata": {},
          "execution_count": 203
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for i in range(A.numberOfLayers):\n",
        "  print('layer'+str(i))\n",
        "  for j in range(A.layers[i].numberOfPerceptrons):\n",
        "    print('percepron'+str(j))\n",
        "    for k in range(A.layers[i].perceptrons[j].numberOfInputs):\n",
        "      print(A.layers[i].perceptrons[j].inputBranchs[k].w)\n"
      ],
      "metadata": {
        "id": "BzVIsbnZzUPT",
        "outputId": "4a7523a5-91d4-4953-dd58-600f053c3d11",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 204,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "layer0\n",
            "percepron0\n",
            "1\n",
            "percepron1\n",
            "1\n",
            "layer1\n",
            "percepron0\n",
            "1\n",
            "1\n",
            "1\n",
            "percepron1\n",
            "1\n",
            "1\n",
            "1\n",
            "layer2\n",
            "percepron0\n",
            "1\n",
            "1\n",
            "1\n",
            "percepron1\n",
            "1\n",
            "1\n",
            "1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "A.layers[0].perceptrons[0].getDelta()\n"
      ],
      "metadata": {
        "id": "mGXPZTAR9aTq",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4bd0fa49-e0f1-4867-c486-f352ad052281"
      },
      "execution_count": 205,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "oooookz [1. 2.]\n",
            "oooookz [1. 2.]\n",
            "oooookz [4. 4.]\n",
            "oooookz [4. 4.]\n",
            "oooookz [4. 4.]\n",
            "oooookz [4. 4.]\n",
            "oooookz [4. 4.]\n",
            "ok -9.0\n",
            "oooookz [4. 4.]\n",
            "ok -8.0\n",
            "oooookz [1. 2.]\n",
            "oooookz [4. 4.]\n",
            "oooookz [4. 4.]\n",
            "ok -9.0\n",
            "oooookz [4. 4.]\n",
            "ok -8.0\n",
            "oooookz [4. 4.]\n",
            "oooookz [4. 4.]\n",
            "ok -9.0\n",
            "oooookz [4. 4.]\n",
            "ok -8.0\n",
            "oooookz [1. 2.]\n",
            "oooookz [1. 2.]\n",
            "ok -17.0\n",
            "oooookz [1. 2.]\n",
            "ok -17.0\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "-34.0"
            ]
          },
          "metadata": {},
          "execution_count": 205
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x=9 \n",
        "q = 1 / (1 + math.exp(-x)) \n",
        "q*(1-q)*(-q)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DGgkOyR7M9rf",
        "outputId": "1848b874-d130-44eb-85ea-bfbc90f9a15e"
      },
      "execution_count": 123,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "-0.00012336412542238054"
            ]
          },
          "metadata": {},
          "execution_count": 123
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "s3iq57kTlCpG"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}